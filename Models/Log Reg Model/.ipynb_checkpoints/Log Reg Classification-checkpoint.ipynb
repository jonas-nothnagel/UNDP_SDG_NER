{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "tknzr = TweetTokenizer()\n",
    "lemm = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.7.4\n",
      "IPython version      : 7.8.0\n",
      "\n",
      "pandas      : 1.2.3\n",
      "scikit-learn: 0.0\n",
      "nltk        : 3.4.5\n",
      "re          : 2.2.1\n",
      "numpy       : 1.19.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p pandas,scikit-learn,nltk,re,numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('17SDGpt2_tweets.csv', lineterminator = '\\n', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    \"\"\"decontracts the words to its expanded form\"\"\"\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(df):\n",
    "    \"\"\"function first creates a copy. Then cleans up text for http, @, ampersands, and clears for punctuations.  Then lemmatizes, tokenizes.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    #decontract\n",
    "    df = df.apply(decontracted)\n",
    "    #clean up https,@, &amp\n",
    "    df = df.apply(lambda x: re.sub(r\"http\\S+\",\"\", x.lower()),1)\\\n",
    "    .apply(lambda i: \" \".join(filter(lambda x: x[0]!=\"@\", i.split())),1)\\\n",
    "    .apply(lambda x: re.sub(r\"&amp\", \"\",x),1)\\\n",
    "    .apply(lambda x: re.sub(r\"&amp;\",\"\",x))\\\n",
    "    .apply(lambda x: re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', x),1)\n",
    "    \n",
    "    #lemmatize\n",
    "    df = df.apply(lambda x: lemm.lemmatize(x))\n",
    "    \n",
    "    #tokenize\n",
    "    df = df.apply(lambda x: tknzr.tokenize(x))\n",
    "    df = df.apply(lambda x: ' '.join(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdg</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>our spousal sponsorship application sent to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>star wars the vintage collection vc186 boba fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>cds is hiring a team lead for our delivery pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>was watching him on show … a person that was r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>as written xiv directly contradicts medical ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sdg                                        clean_tweet\n",
       "0   16  our spousal sponsorship application sent to th...\n",
       "1   16  star wars the vintage collection vc186 boba fe...\n",
       "2   16  cds is hiring a team lead for our delivery pol...\n",
       "3   16  was watching him on show … a person that was r...\n",
       "4   16  as written xiv directly contradicts medical ad..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Clean Tweets column and use only the labels and clean tweets\n",
    "df['clean_tweet'] = clean_tweet(df['tweet'])\n",
    "df = df[~df['clean_tweet'].isnull()]\n",
    "df = df[['sdg', 'clean_tweet']]\n",
    "df['sdg'] = df['sdg'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF vectorizer \n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Column Transformer \n",
    "ct = make_column_transformer(\n",
    "    (tfidf, 'clean_tweet'),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113652, 1), (48708, 1), (113652,), (48708,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['clean_tweet']], df['sdg'], test_size=0.3, random_state=777)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'saga', max_iter = 10000)\n",
    "model = make_pipeline(ct, lr)\n",
    "model.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.83      0.86      1807\n",
      "           2       0.82      0.75      0.79      1798\n",
      "           3       0.66      0.62      0.64      3817\n",
      "           4       0.81      0.90      0.85      6486\n",
      "           5       0.80      0.80      0.80      2366\n",
      "           6       0.81      0.68      0.74      1758\n",
      "           7       0.83      0.75      0.79      2393\n",
      "           8       0.71      0.73      0.72      2408\n",
      "           9       0.79      0.83      0.81      4209\n",
      "          10       0.80      0.73      0.76      2471\n",
      "          11       0.72      0.77      0.74      2898\n",
      "          12       0.90      0.86      0.88      3031\n",
      "          13       0.75      0.69      0.72      2096\n",
      "          14       0.80      0.76      0.78      1660\n",
      "          15       0.81      0.83      0.82      3901\n",
      "          16       0.60      0.69      0.64      3440\n",
      "          17       0.78      0.75      0.76      2169\n",
      "\n",
      "    accuracy                           0.78     48708\n",
      "   macro avg       0.78      0.76      0.77     48708\n",
      "weighted avg       0.78      0.78      0.78     48708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'columntransformer', 'logisticregression', 'columntransformer__n_jobs', 'columntransformer__remainder', 'columntransformer__sparse_threshold', 'columntransformer__transformer_weights', 'columntransformer__transformers', 'columntransformer__verbose', 'columntransformer__tfidfvectorizer', 'columntransformer__tfidfvectorizer__analyzer', 'columntransformer__tfidfvectorizer__binary', 'columntransformer__tfidfvectorizer__decode_error', 'columntransformer__tfidfvectorizer__dtype', 'columntransformer__tfidfvectorizer__encoding', 'columntransformer__tfidfvectorizer__input', 'columntransformer__tfidfvectorizer__lowercase', 'columntransformer__tfidfvectorizer__max_df', 'columntransformer__tfidfvectorizer__max_features', 'columntransformer__tfidfvectorizer__min_df', 'columntransformer__tfidfvectorizer__ngram_range', 'columntransformer__tfidfvectorizer__norm', 'columntransformer__tfidfvectorizer__preprocessor', 'columntransformer__tfidfvectorizer__smooth_idf', 'columntransformer__tfidfvectorizer__stop_words', 'columntransformer__tfidfvectorizer__strip_accents', 'columntransformer__tfidfvectorizer__sublinear_tf', 'columntransformer__tfidfvectorizer__token_pattern', 'columntransformer__tfidfvectorizer__tokenizer', 'columntransformer__tfidfvectorizer__use_idf', 'columntransformer__tfidfvectorizer__vocabulary', 'logisticregression__C', 'logisticregression__class_weight', 'logisticregression__dual', 'logisticregression__fit_intercept', 'logisticregression__intercept_scaling', 'logisticregression__l1_ratio', 'logisticregression__max_iter', 'logisticregression__multi_class', 'logisticregression__n_jobs', 'logisticregression__penalty', 'logisticregression__random_state', 'logisticregression__solver', 'logisticregression__tol', 'logisticregression__verbose', 'logisticregression__warm_start'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparamater Tuning Logistic Regression \n",
    "'''\n",
    "'columntransformer__tfidfvectorizer__max_features', \n",
    "'logisticregression__max_iter'\n",
    "'columntransformer__tfidfvectorizer__ngram_range'\n",
    "'logisticregression__C'\n",
    "'''\n",
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for randomforest to tune \n",
    "params = {}\n",
    "\n",
    "params['columntransformer__tfidfvectorizer__min_df'] = np.arange(0.0001,0.001,0.0001)\n",
    "params['columntransformer__tfidfvectorizer__ngram_range'] = [(1,3), (1,2), (1,1),(2,2), (3,3)]\n",
    "params['logisticregression__C'] = np.arange(0,1,0.1)\n",
    "params['logisticregression__max_iter'] = np.arange(10000,20000,1000)\n",
    "params['logisticregression__solver'] = ['saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(model, params, random_state=777)\n",
    "clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_columntransformer__tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_columntransformer__tfidfvectorizer__min_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.246157</td>\n",
       "      <td>0.136309</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>saga</td>\n",
       "      <td>17000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>{'logisticregression__solver': 'saga', 'logist...</td>\n",
       "      <td>0.759579</td>\n",
       "      <td>0.757820</td>\n",
       "      <td>0.761417</td>\n",
       "      <td>0.765332</td>\n",
       "      <td>0.759041</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.522171</td>\n",
       "      <td>0.498132</td>\n",
       "      <td>1.417569</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>saga</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>{'logisticregression__solver': 'saga', 'logist...</td>\n",
       "      <td>0.756148</td>\n",
       "      <td>0.753728</td>\n",
       "      <td>0.755037</td>\n",
       "      <td>0.760097</td>\n",
       "      <td>0.755829</td>\n",
       "      <td>0.756168</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.910943</td>\n",
       "      <td>0.180703</td>\n",
       "      <td>0.440954</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>saga</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>{'logisticregression__solver': 'saga', 'logist...</td>\n",
       "      <td>0.728521</td>\n",
       "      <td>0.724869</td>\n",
       "      <td>0.728201</td>\n",
       "      <td>0.730796</td>\n",
       "      <td>0.727629</td>\n",
       "      <td>0.728003</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.054611</td>\n",
       "      <td>0.171013</td>\n",
       "      <td>1.368712</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>saga</td>\n",
       "      <td>17000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>{'logisticregression__solver': 'saga', 'logist...</td>\n",
       "      <td>0.714091</td>\n",
       "      <td>0.710659</td>\n",
       "      <td>0.709855</td>\n",
       "      <td>0.715486</td>\n",
       "      <td>0.712407</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.051492</td>\n",
       "      <td>0.323113</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>saga</td>\n",
       "      <td>19000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>{'logisticregression__solver': 'saga', 'logist...</td>\n",
       "      <td>0.708768</td>\n",
       "      <td>0.705600</td>\n",
       "      <td>0.705851</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.706599</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       9.246157      0.136309         0.828516        0.009457   \n",
       "7      13.522171      0.498132         1.417569        0.025169   \n",
       "4       4.910943      0.180703         0.440954        0.014164   \n",
       "1      13.054611      0.171013         1.368712        0.017088   \n",
       "2       9.051492      0.323113         0.826395        0.006932   \n",
       "\n",
       "  param_logisticregression__solver param_logisticregression__max_iter  \\\n",
       "3                             saga                              17000   \n",
       "7                             saga                              18000   \n",
       "4                             saga                              12000   \n",
       "1                             saga                              17000   \n",
       "2                             saga                              19000   \n",
       "\n",
       "  param_logisticregression__C  \\\n",
       "3                         0.8   \n",
       "7                         0.7   \n",
       "4                         0.1   \n",
       "1                         0.1   \n",
       "2                         0.1   \n",
       "\n",
       "  param_columntransformer__tfidfvectorizer__ngram_range  \\\n",
       "3                                             (1, 2)      \n",
       "7                                             (1, 3)      \n",
       "4                                             (1, 1)      \n",
       "1                                             (1, 3)      \n",
       "2                                             (1, 2)      \n",
       "\n",
       "  param_columntransformer__tfidfvectorizer__min_df  \\\n",
       "3                                           0.0006   \n",
       "7                                           0.0008   \n",
       "4                                           0.0009   \n",
       "1                                           0.0009   \n",
       "2                                           0.0005   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'logisticregression__solver': 'saga', 'logist...           0.759579   \n",
       "7  {'logisticregression__solver': 'saga', 'logist...           0.756148   \n",
       "4  {'logisticregression__solver': 'saga', 'logist...           0.728521   \n",
       "1  {'logisticregression__solver': 'saga', 'logist...           0.714091   \n",
       "2  {'logisticregression__solver': 'saga', 'logist...           0.708768   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.757820           0.761417           0.765332           0.759041   \n",
       "7           0.753728           0.755037           0.760097           0.755829   \n",
       "4           0.724869           0.728201           0.730796           0.727629   \n",
       "1           0.710659           0.709855           0.715486           0.712407   \n",
       "2           0.705600           0.705851           0.709063           0.706599   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.760638        0.002617                1  \n",
       "7         0.756168        0.002135                2  \n",
       "4         0.728003        0.001901                3  \n",
       "1         0.712500        0.002090                4  \n",
       "2         0.707176        0.001460                5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the best model results \n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "results.sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7606377703550679"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The best score \n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'lr_finalized_model.sav'\n",
    "pickle.dump(clf.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save modelfitter and columntransformer\n",
    "filename = 'lr_columntransformer.sav'\n",
    "pickle.dump(ct, open(filename, 'wb'))\n",
    "\n",
    "filename = 'lr_model_fit.sav'\n",
    "pickle.dump(model, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('lr_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('val_set_sdg_1_7_8_12_13_toy.csv')\n",
    "df3= pd.read_csv('train_set_sdg_1_7_8_12_13_toy.csv')\n",
    "df4 = pd.read_csv('eval_set_sdg_1_7_8_12_13_curated_journals_toy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The transition from college to work during the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sustainability entrepreneurship and equitable ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Determination of 41 polybrominated diphenyl et...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mainstreaming sustainability into biodiversity...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A modular gene targeting system for sequential...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Policy options for sustainable development in ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>A semi-empirical, electrochemistry-based model...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Impact of natural fractures in reservoir model...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Optimization of the medium composition for the...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>A test of the validity of the \"developing coun...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_tweet  sdg\n",
       "0    The transition from college to work during the...    1\n",
       "1    Sustainability entrepreneurship and equitable ...    8\n",
       "2    Determination of 41 polybrominated diphenyl et...   12\n",
       "3    Mainstreaming sustainability into biodiversity...   12\n",
       "4    A modular gene targeting system for sequential...   12\n",
       "..                                                 ...  ...\n",
       "345  Policy options for sustainable development in ...    8\n",
       "346  A semi-empirical, electrochemistry-based model...    7\n",
       "347  Impact of natural fractures in reservoir model...    8\n",
       "348  Optimization of the medium composition for the...    7\n",
       "349  A test of the validity of the \"developing coun...    8\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = pd.concat([df2,df3,df4], ignore_index = True)\n",
    "df_list= df_list[['title','sdg_id']].rename(columns = {'title':'clean_tweet', 'sdg_id':'sdg'})\n",
    "df_list['sdg'] = df_list['sdg'].astype(int)\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = clf.predict(df_list[['clean_tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 13, 15, 15, 17, 15,  1, 14,  7, 16, 15, 15,  8, 13, 13,  9, 13,\n",
       "       17,  9, 16, 12, 15,  7, 15, 12, 15, 11,  7, 14,  4,  7,  5,  9,  3,\n",
       "       13,  3,  3, 17,  4,  9,  5, 13,  7, 11,  1,  9, 15, 12, 17, 13, 14,\n",
       "        3, 14, 10,  3, 16, 15, 16,  2,  3, 15, 17, 12, 10,  7, 13,  9,  7,\n",
       "       11,  9, 17,  8, 17,  9,  3,  4,  4,  8,  6, 17, 15,  8,  9,  9,  3,\n",
       "       10,  8, 15, 15, 15, 13, 13, 15, 15, 12, 10, 10, 11,  9,  3,  9,  8,\n",
       "       10, 15,  4, 12, 13,  7, 15, 17, 11,  1, 13, 12,  3, 13, 15, 15, 15,\n",
       "        7,  9,  9, 12, 10, 13,  2, 15,  3,  3,  4,  9, 13,  3, 10,  3,  3,\n",
       "        6,  9, 16, 15, 11,  3,  3, 15,  5, 12, 13, 14, 13, 17,  3, 13, 15,\n",
       "        2, 16,  3, 14,  8, 15, 11,  3,  9, 11, 16, 10, 13, 14,  4,  7, 13,\n",
       "        1, 10, 12, 16, 12, 12, 10,  3, 17,  7,  4,  9,  7, 15,  3, 12, 11,\n",
       "        7,  3,  9, 17, 15, 14,  7,  3, 16, 11,  3,  3, 13,  3,  3,  4,  7,\n",
       "        7,  7,  9, 10,  9, 15, 12, 15,  3,  9, 15, 12,  4,  7, 15, 11, 11,\n",
       "       13,  4,  7, 15, 13, 10, 10, 13, 12,  3,  3,  3,  3, 10,  3, 12,  9,\n",
       "        2, 17,  3, 16, 15,  9,  7,  6,  7, 13, 15, 16,  3, 11,  7, 13,  4,\n",
       "        4,  3,  8,  3,  7, 15,  7, 16, 11, 15,  5, 13, 10, 13, 15,  4, 12,\n",
       "       10, 17,  3, 15, 17, 15,  9, 13,  3, 12, 12,  7, 10, 13, 10,  8, 10,\n",
       "       13,  9, 15, 15, 11,  7, 14,  9, 14, 17,  7,  7,  3,  3,  9,  7, 15,\n",
       "        7, 13, 17,  9, 15, 13, 15, 13, 16, 15,  8,  7, 12,  8,  1, 13,  8,\n",
       "        9, 10,  7, 13,  7,  7,  9, 16,  4,  7,  9, 15, 16, 15, 14, 15, 10,\n",
       "        7, 12,  4, 10,  9, 12,  7, 15,  9, 11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.07      0.13        41\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.70      0.22      0.33       119\n",
      "           8       0.69      0.10      0.18        88\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.48      0.23      0.31        48\n",
      "          13       0.58      0.39      0.47        54\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.20       350\n",
      "   macro avg       0.18      0.06      0.08       350\n",
      "weighted avg       0.64      0.20      0.29       350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Performs poorly outside the dataset need to collect more data this way \n",
    "print(classification_report(df_list['sdg'], y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
