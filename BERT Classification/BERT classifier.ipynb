{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc004b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers,scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef24892",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid', palette = 'muted', font_scale = 1.3)\n",
    "rcParams['figure.figsize'] = 14, 9\n",
    "\n",
    "random_seed = 777\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "pl.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff977090",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6918c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('17SDGpt2_tweets.csv', lineterminator='\\n', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(df):\n",
    "    df = df.copy().reset_index(drop = True)\n",
    "    df = df.apply(lambda x: re.sub(r\"http\\S+\", \"\", x), 1)\\\n",
    ".apply(lambda i: \" \".join(filter(lambda x:x[0]!=\"@\", i.split())), 1)\\\n",
    ".apply(lambda x: re.sub(r\"&amp\", \"\",x),1)\\\n",
    ".apply(lambda x: re.sub(r\"&amp;\", \"\",x),1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e506149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = clean_text(df['tweet'])\n",
    "df['clean_tweet'] = df['clean_tweet'].drop_duplicates()\n",
    "df = df[~df['clean_tweet'].isnull()]\n",
    "df = df[['sdg', 'clean_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ac79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size = 0.4)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4129bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['sdg'])\n",
    "plt.xlabel('sdg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98002cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained Model \n",
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = df.iloc[77777]\n",
    "sample_tweet = sample_row['clean_tweet']\n",
    "sample_label = sample_row['sdg']\n",
    "print(sample_tweet, sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(sample_tweet,\n",
    "                                max_length = 150,\n",
    "                                add_special_tokens = True,\n",
    "                                truncation = True,\n",
    "                                return_token_type_ids = False,\n",
    "                                padding = True,\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt')\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding['input_ids'].squeeze()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c22348",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding['attention_mask'].squeeze()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'].squeeze()[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    token_count = len(tokenizer.encode(\n",
    "    row['clean_tweet'],\n",
    "    max_length = 150,\n",
    "    truncation = True))\n",
    "    token_counts.append(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115340ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(token_counts)\n",
    "plt.xlim([0,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee889504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SdgTweetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tweets, sdgs, tokenizer, max_len):\n",
    "        self.tweets = tweets\n",
    "        self.sdgs = sdgs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        sdg = self.sdgs[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            return_token_type_ids = False,\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt')\n",
    "        \n",
    "        return {'tweet_text': tweet,\n",
    "               'input_ids': encoding['input_ids'].flatten(),\n",
    "               'attention_mask': encoding['attention_mask'].flatten(),\n",
    "               'sdg': torch.tensor(sdg, dtype = torch.long)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.4,\n",
    "                                     random_state = random_seed)\n",
    "\n",
    "df_val, df_test = train_test_split(df_test, test_size = 0.5,\n",
    "                                   random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = SdgTweetDataset(\n",
    "        tweets=df.clean_tweet.to_numpy(),\n",
    "        sdgs = df.sdg.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "      )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf22985",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba73d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39102622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0e152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffc0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
